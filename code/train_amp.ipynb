{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e566e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Clone repo (if running on a fresh Kaggle session) and install deps\n",
    "!git clone https://github.com/ShMazumder/Benchmarking-MoR-on-fine-tuned-SLM.git || true\n",
    "%cd Benchmarking-MoR-on-fine-tuned-SLM/code\n",
    "# Install requirements (Kaggle may already have torch; this will install others)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9e1518",
   "metadata": {},
   "source": [
    "## 2) Prepare a patched script `train_amp.py`\n",
    "\n",
    "This cell copies `train.py` to `train_amp.py` and programmatically appends safe overrides for `train_baseline` and `train_mor` that use AMP, save checkpoint every epoch, and collect per-epoch history into JSON files under `results/`. This approach writes the overrides as plain text to avoid f-string interpolation issues during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d76ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "src = Path('train.py')\n",
    "assert src.exists(), 'train.py not found in current directory'\n",
    "dst = Path('train_amp.py')\n",
    "\n",
    "# Reduce epochs for quick tests (edit config.py safely)\n",
    "cfg_path = Path('config.py')\n",
    "if cfg_path.exists():\n",
    "    cfg = cfg_path.read_text()\n",
    "    cfg = cfg.replace('epochs_baseline = 30','epochs_baseline = 3')\n",
    "    cfg = cfg.replace('epochs_mor_exp1 = 30','epochs_mor_exp1 = 3')\n",
    "    cfg = cfg.replace('epochs_mor_exp2 = 50','epochs_mor_exp2 = 5')\n",
    "    cfg_path.write_text(cfg)\n",
    "    print('Updated config.py to smaller epoch counts for quick tests')\n",
    "\n",
    "# Copy base script and append safe overrides written as a plain triple-quoted string\n",
    "dst.write_text(src.read_text())\n",
    "\n",
    "overrides = '''\n",
    "# --- APPENDED OVERRIDES (AMP + checkpointing + history) ---\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import json\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "def train_baseline(model, train_loader, test_loader, config, experiment_name):\n",
    "    device = config.device\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    use_amp = True if str(config.device).startswith('cuda') else False\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    timer = Timer()\n",
    "    history = []\n",
    "    print('\\\\nTraining {}...'.format(experiment_name))\n",
    "    timer.start()\n",
    "    for epoch in range(config.epochs_baseline):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs_baseline}')\n",
    "        for batch_idx, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    logits, effective_depth = model(x)\n",
    "                    loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits, effective_depth = model(x)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            acc = calculate_accuracy(logits, y)\n",
    "            total_loss += float(loss.item())\n",
    "            total_acc += float(acc)\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{acc:.2f}%', 'depth': f'{float(effective_depth):.2f}'})\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={avg_acc:.2f}%')\n",
    "        _Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'epoch': epoch+1, 'model_state': model.state_dict(), 'optimizer': optimizer.state_dict()}, _Path(config.checkpoint_dir)/f'{experiment_name}_epoch{epoch+1}.pt')\n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'acc': avg_acc})\n",
    "    timer.stop()\n",
    "    training_time = timer.get_elapsed()\n",
    "    print('\\\\nEvaluating...')\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            test_acc += float(calculate_accuracy(logits, y))\n",
    "    test_acc /= len(test_loader)\n",
    "    results = {\n",
    "        'experiment': experiment_name,\n",
    "        'model_type': 'baseline',\n",
    "        'n_layers': model.n_layers,\n",
    "        'accuracy': avg_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'effective_depth': float(model.n_layers),\n",
    "        'training_time_seconds': training_time\n",
    "    }\n",
    "    _Path(config.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    save_results(results, f'{config.results_dir}/{experiment_name}.json')\n",
    "    with open(f'{config.results_dir}/{experiment_name}_history.json','w') as f:\n",
    "        json.dump(history, f)\n",
    "    print('\\\\nResults:')\n",
    "    print('  Training Accuracy: {:.2f}%'.format(avg_acc))\n",
    "    print('  Test Accuracy: {:.2f}%'.format(test_acc))\n",
    "    print('  Effective Depth: {}'.format(model.n_layers))\n",
    "    print('  Training Time: {:.0f}s'.format(training_time))\n",
    "    return results\n",
    "\n",
    "def train_mor(model, train_loader, test_loader, config, experiment_name, epochs, lambda_penalty=0.1):\n",
    "    device = config.device\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    use_amp = True if str(config.device).startswith('cuda') else False\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    timer = Timer()\n",
    "    history = []\n",
    "    print('\\\\nTraining {}...'.format(experiment_name))\n",
    "    timer.start()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        total_depth = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for batch_idx, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    logits, effective_depth, routing_stats = model(x, training=True)\n",
    "                    ce_loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                    depth_penalty = lambda_penalty * effective_depth\n",
    "                    loss = ce_loss + depth_penalty\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits, effective_depth, routing_stats = model(x, training=True)\n",
    "                ce_loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                depth_penalty = lambda_penalty * effective_depth\n",
    "                loss = ce_loss + depth_penalty\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            acc = calculate_accuracy(logits, y)\n",
    "            total_loss += float(ce_loss.item())\n",
    "            total_acc += float(acc)\n",
    "            total_depth += float(effective_depth)\n",
    "            pbar.set_postfix({'loss': f'{ce_loss.item():.4f}', 'acc': f'{acc:.2f}%', 'depth': f'{float(effective_depth):.2f}'})\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        avg_depth = total_depth / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={avg_acc:.2f}%, Depth={avg_depth:.2f}')\n",
    "        _Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'epoch': epoch+1, 'model_state': model.state_dict(), 'optimizer': optimizer.state_dict()}, _Path(config.checkpoint_dir)/f'{experiment_name}_epoch{epoch+1}.pt')\n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'acc': avg_acc, 'depth': avg_depth})\n",
    "    timer.stop()\n",
    "    training_time = timer.get_elapsed()\n",
    "    print('\\\\nEvaluating...')\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    test_depth = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, effective_depth, routing_stats = model(x, training=False)\n",
    "            test_acc += float(calculate_accuracy(logits, y))\n",
    "            test_depth += float(effective_depth)\n",
    "    test_acc /= len(test_loader)\n",
    "    test_depth /= len(test_loader)\n",
    "    results = {\n",
    "        'experiment': experiment_name,\n",
    "        'model_type': 'mor',\n",
    "        'n_layers': model.n_layers,\n",
    "        'accuracy': avg_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'effective_depth': avg_depth,\n",
    "        'test_effective_depth': test_depth,\n",
    "        'training_time_seconds': training_time,\n",
    "        'lambda_penalty': lambda_penalty\n",
    "    }\n",
    "    _Path(config.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    save_results(results, f'{config.results_dir}/{experiment_name}.json')\n",
    "    with open(f'{config.results_dir}/{experiment_name}_history.json','w') as f:\n",
    "        json.dump(history, f)\n",
    "    print('\\\\nResults:')\n",
    "    print('  Training Accuracy: {:.2f}%'.format(avg_acc))\n",
    "    print('  Test Accuracy: {:.2f}%'.format(test_acc))\n",
    "    print('  Effective Depth: {:.2f}'.format(avg_depth))\n",
    "    print('  Test Effective Depth: {:.2f}'.format(test_depth))\n",
    "    print('  Training Time: {:.0f}s'.format(training_time))\n",
    "    return results\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31941b8",
   "metadata": {},
   "source": [
    "## 3) Run quick 3-epoch test (MoR)\n",
    "\n",
    "This will use GPU if available and write per-epoch history to `results/MoR_Exp1_history.json` and checkpoints to `checkpoints/.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3feb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MoR quick test (use mor_exp1 for initial test)\n",
    "!python train_amp.py --dataset shakespeare --experiment mor_exp1 --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff818cd",
   "metadata": {},
   "source": [
    "## 4) Plot per-epoch loss/accuracy and short analysis\n",
    "\n",
    "This cell reads the produced history JSON and plots training loss and accuracy per epoch. It also prints a short comparison versus the expected results from the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def find_history(prefixs=('MoR_','Baseline_')):\n",
    "    p = Path('results')\n",
    "    if not p.exists():\n",
    "        print('results/ directory not found')\n",
    "        return None\n",
    "    for pref in prefixs:\n",
    "        cand = list(p.glob(f'{pref}*history.json'))\n",
    "        if cand:\n",
    "            return cand[0]\n",
    "    cand = list(p.glob('*history.json'))\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "hist_path = Path('results/MoR_Exp1_history.json')\n",
    "if not hist_path.exists():\n",
    "    hist_path = find_history(('MoR_','Baseline_'))\n",
    "if not hist_path:\n",
    "    print('No history JSON found in results/. Run the training cell and re-run this cell.')\n",
    "else:\n",
    "    hist = json.load(open(hist_path))\n",
    "    epochs = [h['epoch'] for h in hist]\n",
    "    loss = [h.get('loss', None) for h in hist]\n",
    "    acc = [h.get('acc', None) for h in hist]\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    if any(v is not None for v in loss):\n",
    "        ax1.plot(epochs, loss, '-o', color='tab:red', label='train loss')\n",
    "        ax1.set_ylabel('loss', color='tab:red')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax2 = ax1.twinx()\n",
    "    if any(v is not None for v in acc):\n",
    "        ax2.plot(epochs, acc, '-s', color='tab:blue', label='train acc')\n",
    "        ax2.set_ylabel('accuracy (%)', color='tab:blue')\n",
    "    plt.title(f'Training metrics from {hist_path.name}')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Short analysis\n",
    "    print('\\\\nShort analysis:')\n",
    "    if acc and acc[-1] is not None:\n",
    "        print(f\"  Final training accuracy: {acc[-1]:.2f}%\")\n",
    "    print('  Observed behavior: check routing statistics and effective depth in MoR runs')\n",
    "    print('  Next steps: compare with Baseline, adjust lambda_penalty, or increase epochs for stability')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
