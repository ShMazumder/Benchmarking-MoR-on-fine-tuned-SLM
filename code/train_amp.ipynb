{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Clone repo (if running on a fresh Kaggle session) and install deps\n",
    "!git clone https://github.com/ShMazumder/Benchmarking-MoR-on-fine-tuned-SLM.git || true\n",
    "%cd Benchmarking-MoR-on-fine-tuned-SLM/code\n",
    "# Install requirements (Kaggle may already have torch; this will install others)\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bee87",
   "metadata": {},
   "source": [
    "## 2) Prepare a patched script `train_amp.py`\n",
    "\n",
    "This cell copies `train.py` to `train_amp.py` and programmatically replaces the `train_baseline` and `train_mor` functions with versions that use AMP, save checkpoint every epoch, and collect per-epoch history into JSON files under `results/.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6968fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, sys, re\n",
    "from pathlib import Path\n",
    "p = Path('train.py')\n",
    "assert p.exists(), 'train.py not found in code/'\n",
    "s = p.read_text()\n",
    "\n",
    "# 1) add imports for AMP, JSON (if not already present)\n",
    "s = s.replace(\n",
    "    \"from utils import calculate_accuracy, save_checkpoint, save_results, Timer, print_model_info\",\n",
    "    \"from utils import calculate_accuracy, save_checkpoint, save_results, Timer, print_model_info\\nfrom torch.cuda.amp import autocast, GradScaler\\nimport json\\nfrom pathlib import Path as _Path\"\n",
    ")\n",
    "\n",
    "# 2) reduce epochs defaults by editing config usage at runtime is simpler: we'll patch Config defaults here\n",
    "cfg_path = Path('config.py')\n",
    "cfg = cfg_path.read_text()\n",
    "cfg = cfg.replace('epochs_baseline = 30','epochs_baseline = 3')\n",
    "cfg = cfg.replace('epochs_mor_exp1 = 30','epochs_mor_exp1 = 3')\n",
    "cfg = cfg.replace('epochs_mor_exp2 = 50','epochs_mor_exp2 = 5')\n",
    "cfg_path.write_text(cfg)\n",
    "print('Updated config.py to smaller epoch counts for quick tests')\n",
    "\n",
    "# 3) prepare new train_baseline function (AMP + checkpoint + history)\n",
    "new_baseline = r\"\"\"\n",
    "def train_baseline(model, train_loader, test_loader, config, experiment_name):\n",
    "    device = config.device\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    use_amp = True if config.device.startswith('cuda') else False\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    timer = Timer()\n",
    "    history = []\n",
    "    print(f\"\\nTraining {experiment_name}...\")\n",
    "    timer.start()\n",
    "    for epoch in range(config.epochs_baseline):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs_baseline}\")\n",
    "        for batch_idx, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    logits, effective_depth = model(x)\n",
    "                    loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits, effective_depth = model(x)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            acc = calculate_accuracy(logits, y)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{acc:.2f}%',\n",
    "                'depth': f'{effective_depth:.2f}'\n",
    "            })\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={avg_acc:.2f}%\")\n",
    "        # checkpoint\n",
    "        _Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'epoch': epoch+1, 'model_state': model.state_dict(), 'optimizer': optimizer.state_dict()}, _Path(config.checkpoint_dir)/f'{experiment_name}_epoch{epoch+1}.pt')\n",
    "        # record history\n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'acc': avg_acc})\n",
    "    timer.stop()\n",
    "    training_time = timer.get_elapsed()\n",
    "    print('\\nEvaluating...')\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, _ = model(x)\n",
    "            test_acc += calculate_accuracy(logits, y)\n",
    "    test_acc /= len(test_loader)\n",
    "    results = {\n",
    "        'experiment': experiment_name,\n",
    "        'model_type': 'baseline',\n",
    "        'n_layers': model.n_layers,\n",
    "        'accuracy': avg_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'effective_depth': float(model.n_layers),\n",
    "        'training_time_seconds': training_time\n",
    "    }\n",
    "    # save results and history\n",
    "    _Path(config.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    save_results(results, f'{config.results_dir}/{experiment_name}.json')\n",
    "    with open(f'{config.results_dir}/{experiment_name}_history.json','w') as f:\n",
    "        json.dump(history, f)\n",
    "    print('\\nResults:')\n",
    "    print(f\"  Training Accuracy: {avg_acc:.2f}%\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Effective Depth: {model.n_layers}\")\n",
    "    print(f\"  Training Time: {training_time:.0f}s\")\n",
    "    return results\n",
    "\"\"\"\n",
    "\n",
    "# 4) prepare new train_mor function\n",
    "new_mor = r\"\"\"\n",
    "def train_mor(model, train_loader, test_loader, config, experiment_name, epochs, lambda_penalty=0.1):\n",
    "    device = config.device\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    use_amp = True if config.device.startswith('cuda') else False\n",
    "    scaler = GradScaler() if use_amp else None\n",
    "    timer = Timer()\n",
    "    history = []\n",
    "    print(f\"\\nTraining {experiment_name}...\")\n",
    "    timer.start()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        total_depth = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for batch_idx, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    logits, effective_depth, routing_stats = model(x, training=True)\n",
    "                    ce_loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                    depth_penalty = lambda_penalty * effective_depth\n",
    "                    loss = ce_loss + depth_penalty\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logits, effective_depth, routing_stats = model(x, training=True)\n",
    "                ce_loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
    "                depth_penalty = lambda_penalty * effective_depth\n",
    "                loss = ce_loss + depth_penalty\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            acc = calculate_accuracy(logits, y)\n",
    "            total_loss += ce_loss.item()\n",
    "            total_acc += acc\n",
    "            total_depth += effective_depth.item()\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{ce_loss.item():.4f}',\n",
    "                'acc': f'{acc:.2f}%',\n",
    "                'depth': f'{effective_depth.item():.2f}'\n",
    "            })\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        avg_depth = total_depth / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={avg_acc:.2f}%, Depth={avg_depth:.2f}\")\n",
    "        # checkpoint\n",
    "        _Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save({'epoch': epoch+1, 'model_state': model.state_dict(), 'optimizer': optimizer.state_dict()}, _Path(config.checkpoint_dir)/f'{experiment_name}_epoch{epoch+1}.pt')\n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'acc': avg_acc, 'depth': avg_depth})\n",
    "    timer.stop()\n",
    "    training_time = timer.get_elapsed()\n",
    "    print('\\nEvaluating...')\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_depth = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, effective_depth, routing_stats = model(x, training=False)\n",
    "            test_acc += calculate_accuracy(logits, y)\n",
    "            test_depth += effective_depth.item()\n",
    "    test_acc /= len(test_loader)\n",
    "    test_depth /= len(test_loader)\n",
    "    results = {\n",
    "        'experiment': experiment_name,\n",
    "        'model_type': 'mor',\n",
    "        'n_layers': model.n_layers,\n",
    "        'accuracy': avg_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'effective_depth': avg_depth,\n",
    "        'test_effective_depth': test_depth,\n",
    "        'training_time_seconds': training_time,\n",
    "        'lambda_penalty': lambda_penalty\n",
    "    }\n",
    "    _Path(config.results_dir).mkdir(parents=True, exist_ok=True)\n",
    "    save_results(results, f'{config.results_dir}/{experiment_name}.json')\n",
    "    with open(f'{config.results_dir}/{experiment_name}_history.json','w') as f:\n",
    "        json.dump(history, f)\n",
    "    print('\\nResults:')\n",
    "    print(f\"  Training Accuracy: {avg_acc:.2f}%\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Effective Depth: {avg_depth:.2f}\")\n",
    "    print(f\"  Test Effective Depth: {test_depth:.2f}\")\n",
    "    print(f\"  Training Time: {training_time:.0f}s\")\n",
    "    return results\n",
    "\"\"\"\n",
    "\n",
    "# 5) replace original functions in the file\n",
    "s2 = s\n",
    "s2 = re.sub(r\"def train_baseline\\([\\s\\S]*?return results\\n\\n\", new_baseline + \"\\n\\n\", s2)\n",
    "s2 = re.sub(r\"def train_mor\\([\\s\\S]*?return results\\n\\n\", new_mor + \"\\n\\n\", s2)\n",
    "\n",
    "Path('train_amp.py').write_text(s2)\n",
    "print('Wrote train_amp.py with AMP+checkpointing and history.\\nRun: python train_amp.py --dataset shakespeare --experiment baseline_6 --device cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b138c",
   "metadata": {},
   "source": [
    "## 3) Run quick 3-epoch test (baseline_6) using the patched script\n",
    "\n",
    "This will use GPU if available and write per-epoch history to `results/Baseline_N6_history.json` and checkpoints to `checkpoints/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da840f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the quick test\n",
    "!python train_amp.py --dataset shakespeare --experiment baseline_6 --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9414b65",
   "metadata": {},
   "source": [
    "## 4) Plot per-epoch loss/accuracy and short analysis\n",
    "\n",
    "This cell reads the produced history JSON and plots training loss and accuracy per epoch. It also prints a short comparison versus the expected results from the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "hist_path = Path('results/Baseline_N6_history.json')\n",
    "if not hist_path.exists():\n",
    "    # try the naming pattern used earlier (experiment name in code was Baseline_N6)\n",
    "    hist_candidates = list(Path('results').glob('*history.json'))\n",
    "    if hist_candidates:\n",
    "        hist_path = hist_candidates[0]\n",
    "    else:\n",
    "        print('No history JSON found in results/. Look for files in results/ and adjust path.')\n",
    "if hist_path and hist_path.exists():\n",
    "    hist = json.load(open(hist_path))\n",
    "    epochs = [h['epoch'] for h in hist]\n",
    "    loss = [h['loss'] for h in hist]\n",
    "    acc = [h['acc'] for h in hist]\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(epochs, loss, '-o', color='tab:red', label='train loss')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel('loss', color='tab:red')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, acc, '-s', color='tab:blue', label='train acc')\n",
    "    ax2.set_ylabel('accuracy (%)', color='tab:blue')\n",
    "    plt.title('Training loss and accuracy per epoch')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Short analysis\n",
    "    print('\\nShort analysis:')\n",
    "    print(f\"  Final training accuracy: {acc[-1]:.2f}%\")\n",
    "    # Load README expected numbers for tiny shakespeare (from earlier README notes)\n",
    "    print('  Expected (README): Baseline N=6 test Acc ≈ 39.87% (example)')\n",
    "    print('  Observed: training accuracy is much lower than expected — consider:')\n",
    "    print('    - learning rate, model size, dataset preprocessing or labeling differences')\n",
    "    print('    - try larger epochs, or hyperparameter tuning; verify dataset tokens and vocab mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad184631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4342c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856231a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0f4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da86c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b532ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da264ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eda53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
